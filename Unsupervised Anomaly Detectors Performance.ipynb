{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of different unsupervised anomaly detectors  across different datasets\n",
    "#### Writer: Hamidreza Salahi\n",
    "#### Date: July 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Goal and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This study aims to evaluate the performance of various unsupervised anomaly detection algorithms across multiple datasets. Using the Python Outlier Detection (PyOD) library, we will compare the following models:\n",
    "\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Local Outlier Factor (LOF)\n",
    "- Isolation Forest (IForest)\n",
    "- Kernel Density Estimation (KDE)\n",
    "- Principal Component Analysis (PCA)\n",
    "\n",
    "The datasets selected for this analysis are sourced from the ADbench repository, which includes:\n",
    "\n",
    "- annthyroid\n",
    "- campaign\n",
    "- census\n",
    "- donors\n",
    "- skin\n",
    "\n",
    "The evaluation metric used is the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), with hyperparameters optimized through grid search and cross-validation. Given the large size of these datasets, subsampling with stratification on the target variable $\\textbf{y}$ is employed to maintain the class balance between inliers and outliers. This comprehensive evaluation will provide insights into the effectiveness of different anomaly detection techniques across diverse data scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from pyod.models.knn import KNN  \n",
    "from pyod.models.lof import LOF \n",
    "from pyod.models.iforest import IForest \n",
    "from pyod.models.pca import PCA \n",
    "from pyod.models.kde import KDE \n",
    "import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load datasets and subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annthyroid dataset has 7200 rows, 6 features, mean:0.14430651111111112, standard deviation:0.19154795592282345 and 7.42% outliers\n",
      "campaign dataset has 41188 rows, 62 features, mean:0.22784682179745439, standard deviation:0.40090420621193684 and 11.27% outliers\n",
      "census dataset has 299285 rows, 500 features, mean:0.06630965663919679, standard deviation:0.24769828770621777 and 6.2% outliers\n",
      "donors dataset has 619326 rows, 10 features, mean:0.3276509663837787, standard deviation:0.4354913258213057 and 5.93% outliers\n",
      "skin dataset has 245057 rows, 3 features, mean:-1.3855743303063907e-16, standard deviation:0.9999979596562837 and 20.75% outliers\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset from ADbench\n",
    "adbench_dir = '../../anaconda3/lib/python3.10/site-packages/adbench/datasets/Classical/' \n",
    "dataset_names = ['2_annthyroid', '5_campaign', '9_census', '11_donors','33_skin' ]  \n",
    "outliers_dict = {}\n",
    "for dataset in dataset_names:\n",
    "    data = np.load(adbench_dir+dataset+'.npz', allow_pickle=True)\n",
    "    dataset_name = dataset.split(\"_\")[1].split(\".\")[0]\n",
    "    outliers = round(sum(data[\"y\"]/len(data[\"y\"])*100),2)\n",
    "    outliers_dict[dataset_name] = outliers\n",
    "    print(f'{dataset_name} dataset has {len(data[\"y\"])} rows, {data[\"X\"].shape[1]} features,'\n",
    "          f' mean:{np.mean(data[\"X\"])}, standard deviation:{np.std(data[\"X\"])} and {outliers}% outliers')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note:\n",
    "None of the datasets are standardized (mean = 0, stdv = 1) except for skin dataset. The models which use a distance metric such as PCA, KNN and LOF require scaling. I will apply StandardScaler separately to training and test data to prevent data leakage when it comes to data modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Due to the limitation of computation power, I will be exploiting subsampling, keeping only 1000 data points from each dataset and saving the new subsamples as a dictionary with keys being the name of the dataset and values being $\\textbf{X,y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows in the subsample\n",
    "n_subsample = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold the data\n",
    "datasets = {}\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    data = np.load(adbench_dir + dataset+'.npz', allow_pickle=True)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    data_combined = np.hstack((X, y.reshape(-1, 1)))  # Combine X and y to keep them together during sampling\n",
    "    subsampled_data = resample(data_combined, n_samples=n_subsample, stratify=y, random_state=42)  # Subsample the data while maintaining the class distribution\n",
    "    # Separate the subsample into features and target variable\n",
    "    X_subsample = subsampled_data[:, :-1]\n",
    "    y_subsample = subsampled_data[:, -1]\n",
    "    # Store the subsampled data\n",
    "    datasets[dataset] = (X_subsample, y_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annthyroid subsamplle has 1000 rows, 6 features and 7.4% outliers, actual annthyroid dataset has 7.42% outliers \n",
      "campaign subsamplle has 1000 rows, 62 features and 11.3% outliers, actual campaign dataset has 11.27% outliers \n",
      "census subsamplle has 1000 rows, 500 features and 6.2% outliers, actual census dataset has 6.2% outliers \n",
      "donors subsamplle has 1000 rows, 10 features and 5.9% outliers, actual donors dataset has 5.93% outliers \n",
      "skin subsamplle has 1000 rows, 3 features and 20.8% outliers, actual skin dataset has 20.75% outliers \n"
     ]
    }
   ],
   "source": [
    "# sanity check for subsample with regards to outliers\n",
    "for dataset, (X, y) in datasets.items():\n",
    "    dataset_name = dataset.split(\"_\")[1].split(\".\")[0]\n",
    "    print(f'{dataset_name} subsamplle has {len(y)} rows, {X.shape[1]} features and {round(sum(y/len(y)*100),2)}% outliers, actual {dataset_name} dataset has {outliers_dict[dataset_name]}% outliers ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The % of the outliers in the subsample data is consistent with the actual dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling, Hyperparameters optimization and storing the best model across the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, multiple unsupervised anomaly detection models are trained using the PyOD library. Hyperparameters for each model are optimized through manually performed grid search and cross-validation, as GridSearchCV is not consistent with unsupervised learning and ROC AUC scoring. After identifying the best set of hyperparameters, we evaluate each model using the AUC-ROC metric. The best-performing model for each dataset is saved for future analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the anomaly detection models and their hyperparameters\n",
    "models = {\n",
    "   \n",
    "    'KNN': {\n",
    "        'model': KNN,\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 10, 15],\n",
    "            'method': ['largest', 'mean', 'median'],\n",
    "            'contamination': [0.05, 0.1, 0.15, 0.2]\n",
    "        }\n",
    "    },\n",
    "        'LOF': {\n",
    "        'model': LOF,\n",
    "        'params': {\n",
    "          'n_neighbors': [5, 10,20,30],\n",
    "            'contamination': [0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "                }\n",
    "    },\n",
    "    'IForest': {\n",
    "        'model': IForest,\n",
    "        'params': {\n",
    "            'n_estimators': [50, 75, 100, 150],\n",
    "            'max_features': [0.05, 0.1, 0.15, 0.2],\n",
    "            'contamination': [0.05, 0.1, 0.15, 0.2]\n",
    "        }\n",
    "    },\n",
    "    'PCA': {\n",
    "        'model': PCA,\n",
    "        'params': {\n",
    "            \n",
    "            'whiten': [True, False],\n",
    "            'contamination': [0.05, 0.1, 0.15, 0.2]\n",
    "        }\n",
    "    },\n",
    "    'KDE': {\n",
    "        'model': KDE,\n",
    "        'params': {\n",
    "            'leaf_size': [10, 20, 30, 40],\n",
    "            'contamination': [0.05, 0.1, 0.15, 0.2]\n",
    "           \n",
    "        }\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "results = []\n",
    "        \n",
    "for dataset, (X, y) in datasets.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    # Apply StandardScaler to training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Transform test data using the same scaler\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    for model_name, model_info in models.items():\n",
    "        model_class = model_info['model']  # This should be the class, not an instance\n",
    "        param_combinations = list(itertools.product(*(model_info['params'][param] for param in model_info['params'])))\n",
    "        \n",
    "        best_auc_roc = 0\n",
    "        best_model = None\n",
    "        best_params = None\n",
    "        \n",
    "        for param_combination in param_combinations:\n",
    "            params = {param: value for param, value in zip(model_info['params'].keys(), param_combination)}\n",
    "            model = model_class(**params)\n",
    "            \n",
    "             # Manual cross-validation\n",
    "            skf = StratifiedKFold(n_splits=5)\n",
    "            auc_scores = []\n",
    "            \n",
    "            for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "                X_train_cv, X_val_cv = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "                y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "                \n",
    "                model.fit(X_train_cv)\n",
    "                y_pred = model.decision_function(X_val_cv)\n",
    "                \n",
    "                auc_roc = roc_auc_score(y_val_cv, y_pred)\n",
    "                \n",
    "                auc_scores.append(auc_roc)\n",
    "            \n",
    "            avg_auc_roc = np.mean(auc_scores)\n",
    "            \n",
    "            # Update best model if the current one is better\n",
    "            if avg_auc_roc > best_auc_roc:\n",
    "                best_auc_roc = avg_auc_roc\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "        y_pred_test = best_model.decision_function(X_test_scaled)\n",
    "        test_auc_roc = roc_auc_score(y_test, y_pred_test)\n",
    "        # Store the best model results\n",
    "        results.append({\n",
    "            'dataset': dataset.split(\"_\")[1].split(\".\")[0],\n",
    "            'model': model_name,\n",
    "            'best_params': best_params,\n",
    "            'best_auc_roc': best_auc_roc,\n",
    "            'test_auc_roc': test_auc_roc,\n",
    "            'best_model': best_model\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_569e2_row0_col0, #T_569e2_row1_col0, #T_569e2_row2_col2, #T_569e2_row3_col0, #T_569e2_row4_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_569e2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_569e2_level0_col0\" class=\"col_heading level0 col0\" >IForest</th>\n",
       "      <th id=\"T_569e2_level0_col1\" class=\"col_heading level0 col1\" >KDE</th>\n",
       "      <th id=\"T_569e2_level0_col2\" class=\"col_heading level0 col2\" >KNN</th>\n",
       "      <th id=\"T_569e2_level0_col3\" class=\"col_heading level0 col3\" >LOF</th>\n",
       "      <th id=\"T_569e2_level0_col4\" class=\"col_heading level0 col4\" >PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >dataset</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_569e2_level0_row0\" class=\"row_heading level0 row0\" >annthyroid</th>\n",
       "      <td id=\"T_569e2_row0_col0\" class=\"data row0 col0\" >0.8963</td>\n",
       "      <td id=\"T_569e2_row0_col1\" class=\"data row0 col1\" >0.6524</td>\n",
       "      <td id=\"T_569e2_row0_col2\" class=\"data row0 col2\" >0.6931</td>\n",
       "      <td id=\"T_569e2_row0_col3\" class=\"data row0 col3\" >0.6735</td>\n",
       "      <td id=\"T_569e2_row0_col4\" class=\"data row0 col4\" >0.6372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_569e2_level0_row1\" class=\"row_heading level0 row1\" >campaign</th>\n",
       "      <td id=\"T_569e2_row1_col0\" class=\"data row1 col0\" >0.7437</td>\n",
       "      <td id=\"T_569e2_row1_col1\" class=\"data row1 col1\" >0.6639</td>\n",
       "      <td id=\"T_569e2_row1_col2\" class=\"data row1 col2\" >0.7329</td>\n",
       "      <td id=\"T_569e2_row1_col3\" class=\"data row1 col3\" >0.7106</td>\n",
       "      <td id=\"T_569e2_row1_col4\" class=\"data row1 col4\" >0.7177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_569e2_level0_row2\" class=\"row_heading level0 row2\" >census</th>\n",
       "      <td id=\"T_569e2_row2_col0\" class=\"data row2 col0\" >0.6742</td>\n",
       "      <td id=\"T_569e2_row2_col1\" class=\"data row2 col1\" >0.6715</td>\n",
       "      <td id=\"T_569e2_row2_col2\" class=\"data row2 col2\" >0.6850</td>\n",
       "      <td id=\"T_569e2_row2_col3\" class=\"data row2 col3\" >0.5915</td>\n",
       "      <td id=\"T_569e2_row2_col4\" class=\"data row2 col4\" >0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_569e2_level0_row3\" class=\"row_heading level0 row3\" >donors</th>\n",
       "      <td id=\"T_569e2_row3_col0\" class=\"data row3 col0\" >0.8608</td>\n",
       "      <td id=\"T_569e2_row3_col1\" class=\"data row3 col1\" >0.7904</td>\n",
       "      <td id=\"T_569e2_row3_col2\" class=\"data row3 col2\" >0.8236</td>\n",
       "      <td id=\"T_569e2_row3_col3\" class=\"data row3 col3\" >0.6062</td>\n",
       "      <td id=\"T_569e2_row3_col4\" class=\"data row3 col4\" >0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_569e2_level0_row4\" class=\"row_heading level0 row4\" >skin</th>\n",
       "      <td id=\"T_569e2_row4_col0\" class=\"data row4 col0\" >0.5924</td>\n",
       "      <td id=\"T_569e2_row4_col1\" class=\"data row4 col1\" >0.6502</td>\n",
       "      <td id=\"T_569e2_row4_col2\" class=\"data row4 col2\" >0.7686</td>\n",
       "      <td id=\"T_569e2_row4_col3\" class=\"data row4 col3\" >0.3726</td>\n",
       "      <td id=\"T_569e2_row4_col4\" class=\"data row4 col4\" >0.4001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1277cf3d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lists to hold data for DataFrame construction\n",
    "datasets_list = []\n",
    "models_list = []\n",
    "auc_rocs_lists = []\n",
    "\n",
    "# Populate lists with results\n",
    "for result in results:\n",
    "    datasets_list.append(result['dataset'])\n",
    "    models_list.append(result['model'])\n",
    "    auc_rocs_lists.append(result['best_auc_roc'])\n",
    "\n",
    "# Create a dictionary to construct the DataFrame\n",
    "data_dict = {\n",
    "    'dataset': datasets_list,\n",
    "    'model': models_list,\n",
    "    'best_auc_roc': auc_rocs_lists\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Pivot the DataFrame to have models as columns\n",
    "results_df = results_df.pivot_table(index=['dataset'], columns='model', values='best_auc_roc').reset_index()\n",
    "\n",
    "# Highlight the highest value in each row\n",
    "def highlight_max_row(row):\n",
    "    # Find the maximum value in the row\n",
    "    max_val = row.max()\n",
    "    # Create a Series to hold the styles\n",
    "    styles = ['' if v != max_val else 'font-weight: bold' for v in row]\n",
    "    return styles\n",
    "\n",
    "# Apply the highlight_max_row function row-wise\n",
    "results_df = results_df.set_index(['dataset'])  # Set the index for row-wise operation\n",
    "results_df = results_df.style.apply(highlight_max_row, axis=1).format(precision=4)\n",
    "\n",
    "# Display the styled DataFrame\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the styled DataFrame to an Excel file\n",
    "results_df.to_excel('anomaly_detection_results.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment with outlier ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intriguing experiment involves varying the outlier ratio in each dataset to analyze model performance as a function of this ratio. To accomplish this, I first create subsamples of each dataset with outlier ratios of 5%, 10%, 15%, and 20%. Using the same methodology as previously employed (grid search and cross-validation), I determine the optimal hyperparameters for each model. This approach allows us to evaluate and compare model performance across different outlier ratios effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define desired outlier percentages\n",
    "outlier_percentages = [0.05, 0.10, 0.15, 0.2]\n",
    "\n",
    "\n",
    "# Dictionary to hold the data\n",
    "datasets = {perc: {} for perc in outlier_percentages}\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    data = np.load(adbench_dir + dataset + '.npz', allow_pickle=True)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    \n",
    "    # Identify inliers and outliers\n",
    "    inliers = X[y == 0]\n",
    "    outliers = X[y == 1]\n",
    "    \n",
    "    for perc in outlier_percentages:\n",
    "        # Calculate the number of inliers and outliers needed\n",
    "        n_outliers = int(n_subsample * perc)\n",
    "        n_inliers = n_subsample - n_outliers\n",
    "        \n",
    "        # Resample inliers and outliers separately\n",
    "        resampled_inliers = resample(inliers, n_samples=n_inliers, random_state=42)\n",
    "        resampled_outliers = resample(outliers, n_samples=n_outliers, random_state=42)\n",
    "        \n",
    "        # Combine resampled inliers and outliers\n",
    "        X_subsample = np.vstack((resampled_inliers, resampled_outliers))\n",
    "        y_subsample = np.hstack((np.zeros(n_inliers), np.ones(n_outliers)))\n",
    "        \n",
    "        # Shuffle the combined data to mix inliers and outliers\n",
    "        combined_data = np.hstack((X_subsample, y_subsample.reshape(-1, 1)))\n",
    "        np.random.shuffle(combined_data)\n",
    "        \n",
    "        # Split back into features and target\n",
    "        X_subsample = combined_data[:, :-1]\n",
    "        y_subsample = combined_data[:, -1]\n",
    "        \n",
    "        # Store the subsampled data\n",
    "        datasets[perc][dataset] = (X_subsample, y_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "results = []\n",
    "for perc, dataset_dict in datasets.items():\n",
    "    for dataset, (X, y) in dataset_dict.items():        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "        # Apply StandardScaler to training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Transform test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        for model_name, model_info in models.items():\n",
    "            model_class = model_info['model']  # This should be the class, not an instance\n",
    "            param_combinations = list(itertools.product(*(model_info['params'][param] for param in model_info['params'])))\n",
    "\n",
    "            best_auc_roc = 0\n",
    "            best_model = None\n",
    "            best_params = None\n",
    "\n",
    "            for param_combination in param_combinations:\n",
    "                params = {param: value for param, value in zip(model_info['params'].keys(), param_combination)}\n",
    "                model = model_class(**params)\n",
    "\n",
    "                 # Manual cross-validation\n",
    "                skf = StratifiedKFold(n_splits=5)\n",
    "                auc_scores = []\n",
    "\n",
    "                for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "                    X_train_cv, X_val_cv = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "                    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                    model.fit(X_train_cv)\n",
    "                    y_pred = model.decision_function(X_val_cv)\n",
    "\n",
    "                    auc_roc = roc_auc_score(y_val_cv, y_pred)\n",
    "\n",
    "                    auc_scores.append(auc_roc)\n",
    "\n",
    "                avg_auc_roc = np.mean(auc_scores)\n",
    "\n",
    "                # Update best model if the current one is better\n",
    "                if avg_auc_roc > best_auc_roc:\n",
    "                    best_auc_roc = avg_auc_roc\n",
    "                    best_model = model\n",
    "                    best_params = params\n",
    "            y_pred_test = best_model.decision_function(X_test_scaled)\n",
    "            test_auc_roc = roc_auc_score(y_test, y_pred_test)\n",
    "            # Store the best model results\n",
    "            results.append({\n",
    "                'dataset': dataset.split(\"_\")[1].split(\".\")[0],\n",
    "                'model': model_name,\n",
    "                'outlier_percentage': perc,\n",
    "                'best_params': best_params,\n",
    "                'best_auc_roc': best_auc_roc,\n",
    "                'test_auc_roc': test_auc_roc,\n",
    "                'best_model': best_model\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create lists to hold data for DataFrame construction\n",
    "datasets_list = []\n",
    "outlier_percentages = []\n",
    "models_list = []\n",
    "auc_rocs_list = []\n",
    "\n",
    "# Populate lists with results\n",
    "for result in results:\n",
    "    datasets_list.append(result['dataset'])\n",
    "    outlier_percentages.append(result['outlier_percentage']*100)\n",
    "    models_list.append(result['model'])\n",
    "    auc_rocs_list.append(result['test_auc_roc'])\n",
    "\n",
    "# Create a dictionary to construct the DataFrame\n",
    "data_dict = {\n",
    "    'dataset': datasets_list,\n",
    "    'outlier_percentage': outlier_percentages,\n",
    "    'model': models_list,\n",
    "    'test_auc_roc': auc_rocs_list\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Pivot the DataFrame to have models as columns\n",
    "results_df = results_df.pivot_table(index=['dataset', 'outlier_percentage'], columns='model', values='test_auc_roc').reset_index()\n",
    "# Highlight the highest value in each row\n",
    "def highlight_max_row(row):\n",
    "    # Find the maximum value in the row\n",
    "    max_val = row.max()\n",
    "    # Create a Series to hold the styles\n",
    "    styles = ['' if v != max_val else 'font-weight: bold' for v in row]\n",
    "    return styles\n",
    "\n",
    "# Apply the highlight_max_row function row-wise\n",
    "results_df = results_df.set_index(['dataset', 'outlier_percentage'])  # Set the index for row-wise operation\n",
    "results_df = results_df.style.apply(highlight_max_row, axis=1).format(precision=4)\n",
    "\n",
    "# Save the styled DataFrame to an Excel file\n",
    "results_df.to_excel('anomaly_detection_results_different_outlier.xlsx', engine='openpyxl')\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
